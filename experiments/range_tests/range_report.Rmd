---
title: "range_report"
author: "odenas"
date: "`r format(Sys.time(), '%e %B %Y')`"
output:
  pdf_document: 
    keep_tex: true
    fig_caption: true
    number_sections: true
  html_document: default
editor_options:
  chunk_output_type: console
urlcolor: blue
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)
library(tidyverse)
```

Range queries take as input a pair of positions in the MS
vector of the type $[a, b)$ (with $0 \leq a \leq b \leq |query|$)
and return a function of MS values in those positions. We consider
here the `sum` and `max` of MS values in a range.

```{r}
rm(list=ls())

#rel_diff_f <- function(a, b) (a - b) / pmax(a, b)
#base_dir <- "./vanilla_compression_techniques/sum"

read_time_dataset <- function(csv_path, input_id){
  time_dd <- (
    read_csv(csv_path)
  )  %>% mutate(time_ms_pq = time_ms / nqueries, dset=input_id)
  time_dd
}

get_data <- function(operation, dset="mm"){
  base_dir <- sprintf("./vanilla_compression_techniques/%s", operation)
  time_dd <- rbind(
    read_time_dataset(sprintf("%s/%s.t.ms.csv", base_dir, dset), dset)
  )
  time_dd %>% mutate(op = operation)
}

```
## djamal speedup
The trivial approach is to keep a partial sum (resp. a current max) as the values of MS that fall in the input
interval are encountered . This approach needs to issue a select query in `ms`
and a linear time scan of the corresponding bit vector portion (`range.bit`).

One can speedup scanning of the `ms` portion by parsing whole words of 64 bits.
We call this the djamal algorithm in the plots. We implemented this also 
for various compression methods in SDSL and RLE based compression. Figure \ref{fig_1} below
shows the performance of these implementations as a function of range size for two datasets. Dataset
HG03061-2 is from two human genomes, hence representing very similar index and query. This dataset
provides substantial speedups for RLE compression.

```{r ciao, fig.cap = "Speedup obtained from scaning by words instead of bits as a function of query size. Panels represent compression and dataset combinations. \\label{fig_1}", fig.height=6, fig.width=10}
dd <- (rbind(get_data("sum"), get_data("max"), get_data("sum", "HG03061-2"), get_data("max", "HG03061-2"))
  %>% filter(method == 'algorithm', block_size==0, compression != "rrr")
  %>% select(-method, -block_size, -time_ms_pq)
  %>% pivot_wider(names_from = algo, values_from = time_ms)
  %>% mutate(speedup = trivial / djamal)
)

ggplot(dd, aes(range_size, speedup, color=op)) +
  geom_line() + geom_point() + 
  expand_limits(y=c(0, 1)) +
  scale_x_log10() + scale_y_log10() +
  labs(subtitle = sprintf("djamal speedup on trivial algorithm (1 measurement of %d queries)", unique(dd$nqueries)),
       y="trivial / djamal") + facet_wrap(compression~dset, scales = "free_y")
```

## Indexed queries
If multiple range queries are expected, an index data structure
can speedup queries. 

In the case of `sum` operations, 
the index stores partial sum values at fixed size blocks of size $B$ (block spanning
strings of `0`s are counted in the next block).
For a given range $[0, h)$ the algorithm issues a select query 
to find the `ms` position of the endpoint, $H = pB + q$, with $p,q$ non-negative
integers and $q < B$. The first component
is obtained in constant time from the partial sums. The second is computed 
by scanning the `ms` array. Generic ranges $[l, h)$ are computed as the difference
between the answers of $[0, h)$ and $[0, l)$.
The time is proportional to $q$ and hence $B$ alone, as shown in Figure \ref{fig_2}.


In the case of `max` operations, the index
stores local max values at fixed size blocks (as above block spanning
strings of `0`s are counted in the next block). The query $[L, H)$ in `ms` space
can be written as $PIQ$ with
$0 \leq P,Q < B$
and $I = qB$ with $q$ a non-negative integer.
Depending on the query length there are three cases to consider:

 * $H-L < B$ implies that $q = 0$ hence we default to the trivial case
 * $B \leq H-L < 2B$ implies that $q = 0$ as above, or $q = 1$ hence a
   constant time look up for the max of the fully contained block plus a
   trivial scan of size $B$ at most.
 * $H-L \geq 2B$ implies that $q > 1$, hence an RMQ look up for the max
   of all the fully contained blocks plus a trivial scan of size $B$ at most.

Figure \ref{fig_2} shows this behavior with the vertical lines representing
$H-L$ for $h-l = B$ and the horizontal lines the time of the algorithm for that
range size.

```{r ciao1, fig.cap = "figure caption. \\label{fig_2}", fig.height=6, fig.width=10}
dd <- (
  rbind(get_data("sum"), get_data("max"))
  %>% filter(compression=='none', algo == 'trivial', !(block_size %in% c(4, 128)))
  %>% select(-algo, -compression)
)
time_dd <- (dd %>% filter(method == 'algorithm'))

size_dd <- (
  dd 
  %>% filter(method=='range.bit', block_size > 0)
  %>% select(op, dset, method, block_size, range_size, time_ms_pq) %>% rename(brsize = time_ms_pq)
  %>% group_by(op, dset, block_size) %>% mutate(d = rank(abs(block_size - range_size)))
  %>% ungroup() %>% filter(d == 1) %>% select(-d)
) %>% inner_join(time_dd
                 %>% group_by(op, dset, block_size)
                 %>% summarise(label_y = 9/10 * max(time_ms)), by = c('op', 'dset', 'block_size'))

avg_dd <- (time_dd %>% group_by(op, dset, block_size) %>% filter(range_size > 2*block_size)
  %>% inner_join(size_dd , by = c('op', 'dset', 'block_size'))
  %>% group_by(op, block_size)
  %>% summarise(time_ms = mean(time_ms)))
avg_dd

ggplot(time_dd, aes(range_size, time_ms, group=factor(block_size))) +
  geom_line(aes(color=factor(block_size))) +  geom_point(aes(color=factor(block_size))) + 
  geom_vline(data = size_dd, aes(xintercept=brsize, color=factor(block_size)), linetype="dashed", alpha=1) +
  geom_text(data = size_dd, aes(brsize, label_y, label=format(round(brsize, 0), big.mark = ",", scientific = FALSE), angle=90), size=3) +
  geom_hline(data = avg_dd, aes(yintercept=time_ms, color=factor(block_size)), linetype="dashed", alpha=1) +
  geom_text(data = avg_dd, aes(1, time_ms, label=format(round(time_ms, 2), big.mark = ",", scientific = FALSE)), size=3) +
  #expand_limits(y=c(0, 1)) +
  scale_y_log10() + scale_x_log10() +
  labs(subtitle = "trivial algorithm, uncompressed") + facet_wrap(dset ~ op, scales = "free_y")
```

### Djamal on indexed queries
We also applied the djamal algorithm on indexed queries.

```{r ciao2, fig.cap = "figure caption. \\label{figurelabel2}", fig.height=6, fig.width=12}
dd <- (rbind(get_data("sum"), get_data("max"))
  %>% filter(method == "algorithm")
  %>% select(-nqueries, -method, -dset, -time_ms_pq)
  %>% pivot_wider(names_from = algo, values_from = time_ms)
  %>% mutate(speedup = trivial / djamal)
)

ggplot(dd, aes(range_size, speedup, color=factor(block_size))) +
  geom_line() + geom_point() +
  scale_x_log10() + scale_y_log10() +
  facet_grid(op~compression) +
  labs(subtitle = "djamal / trivial ", y="trivial / djamal")
```


## Space (MB)
### `ms` compression sizes

```{r}
read_sizes_dataset <- function(input_id){
  get_size <- function(e){
    file.info(sprintf('./vanilla_compression_techniques/%s.t.ms.%s', input_id, e))$size
  }
  space_dd <- (
    tibble(compression = c('none', 'rle', 'rrr'))
    %>% mutate(size = sapply(compression, get_size) / (1024*1024), dset = input_id)
  )
  space_dd  
}

rbind(read_sizes_dataset('mm'))
```

### `rmq` sizes (max)


```{r}
read_rmq_size <- function(dset){
  bd <- './vanilla_compression_techniques/max'
  read_csv(sprintf('%s/%s.t.ms.none.rmq.csv', bd, dset)) %>% mutate(dset = dset, size = size / (1024*1024))
}

rbind(read_rmq_size('mm'), read_rmq_size('HG03061-2')) %>% pivot_wider(names_from = itm, values_from = size)
```

`rmq` sizes


```{r}
read_csv('./vanilla_compression_techniques/max/query.t.ms.none.rmq.csv') %>% mutate(size = size / (1024*1024)) %>% pivot_wider(names_from = itm, values_from = size)
```

