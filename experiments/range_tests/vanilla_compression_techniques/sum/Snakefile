import os
from pathlib import Path
import numpy as np
import pandas as pd

configfile: "../config.yaml"

compression_modes = ["none", "rrr"] #config['compression_modes']
block_sizes = config["block_sizes"]
range_sizes = config['range_sizes']
from_max_idx = config['from_max_idx']
msids = config["species"]

config['rq_profile_exe'] = os.path.join('..', config['rq_profile_exe'])
config['dump_ridx_exe'] = os.path.join('..', config['dump_ridx_exe'])


wildcard_constraints:
    compress="(" + ")|(".join(compression_modes) + ")",
    range="\d+",
    algo="(" + ")|(".join(config['algo']) + ")",
    msid="(" + ")|(".join(msids) + ")"


rule all:
    input:
        "profile.csv", "ridx_sizes.csv"


rule ridx_sizes:
    input:
        expand("{m}/{m}.ms.none.{b}.ridx", b=block_sizes, m=msids)
    output:
        "ridx_sizes.csv"
    threads: 1
    run:
        (pd.DataFrame([(Path(p).name, Path(p).stat().st_size)
                       for p in input], columns=["name", "size"])
         .to_csv(str(output), index=False))


rule collect_profiles:
    threads: 1
    input:
        expand("{m}/{m}.ms.{b}.{r}.{c}.{a}.csv",
            b=block_sizes, r=range_sizes, c=compression_modes, a=config['algo'], m=msids),
        expand("{m}/{m}.ms.0.{r}.{c}.{a}.csv",
            r=range_sizes, c=compression_modes, a=config['algo'], m=msids)
    output:
        "profile.csv"
    run:
        col_names = "compression,block_size,range_size,nqueries,algo,method,time_ms".split(",")
        (pd.concat([pd.read_csv(i, header=None, names=col_names).assign(fn=Path(i).stem) for i in input])
         .to_csv(str(output), index=False))


rule index_profile:
    wildcard_constraints:
        block_size="[1-9]\d*",
    threads: 1
    input:
        ms="{msid}/{msid}.ms.{compress}",
        ridx="{msid}/{msid}.ms.none.{block_size}.ridx"
    output:
        "{msid}/{msid}.ms.{block_size}.{range}.{compress}.{algo}.csv"
    params:
        exec_path=Path(config["rq_profile_exe"]),
        compression=lambda wildcards, input: wildcards.compress,
        block_size=lambda wildcards, input: wildcards.block_size,
        range_size=lambda wildcards, input: wildcards.range,
        algo=lambda wildcards, input: wildcards.algo,
        op="sum",
        from_max_idx=from_max_idx,
        niter=100
    wrapper:
        "file:../../../../fast_ms/wrappers/range_queries_profile"


rule noindex_profile:
    wildcard_constraints:
        block_size="[0]",
    threads: 1
    input:
        ms="{msid}/{msid}.ms.{compress}",
    output:
        "{msid}/{msid}.ms.{block_size}.{range}.{compress}.{algo}.csv"
    params:
        exec_path=Path(config["rq_profile_exe"]),
        compression=lambda wildcards, input: wildcards.compress,
        block_size=lambda wildcards, input: wildcards.block_size,
        range_size=lambda wildcards, input: wildcards.range,
        algo=lambda wildcards, input: wildcards.algo,
        op="sum",
        from_max_idx=from_max_idx,
        niter=20, #lambda wildcards, input: max(5, 30 - max(0, int(np.log2(wildcards.range) + 5)))
    wrapper:
        "file:../../../../fast_ms/wrappers/range_queries_profile"


rule ridx:
    threads: 1
    input:
        "{msid}/{msid}.ms.none"
    benchmark:
        "benchmark/{msid}.ridx_time.{block_size}.tsv"
    output:
        "{msid}/{msid}.ms.none.{block_size}.ridx"
    params:
        exe=config["dump_ridx_exe"]
    shell:
        ("{params.exe} "
         "-ms_path {input} "
         "-block_size {wildcards.block_size} "
         "-op sum ")

rule compressed_input:
    threads: 1
    input:
        "../{msid}.ms.{compress}"
    output:
        "{msid}/{msid}.ms.{compress}"
    shell:
        ("cp -v {input} {output} ")
