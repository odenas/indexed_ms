from pathlib import Path
import csv
import fileinput
import re
import numpy as np

ms_path=Path("human_chimp_from_fabio.ms")
split_exe = Path("../../../../fast_ms/bin/split_ms.x")
compr_exe = Path("../../../../fast_ms/bin/compress_ms.x")
assert ms_path.exists() and split_exe.exists() and compr_exe.exists()

ms_size=6264717366
block_size = 100000000
block_coords = [(s, min(s + block_size, ms_size))
                for s in range(0, ms_size, block_size)]
start_coords, end_coords = zip(*block_coords)
block_type = "fixed_size"
compression_modes = ["rrr", "rle"]


wildcard_constraints:
    compr = "(" + ")|(".join(compression_modes) + ")",
    start = "\d+",
    end = "\d+"


rule all:
    input:
        ["fixed_size_%d_%d.none" % coord for coord in block_coords],
        ["fixed_size_%d_%d.none.rrr" % coord for coord in block_coords],
        ["fixed_size_%d_%d.none.rle" % coord for coord in block_coords]
    output:
        "sizes.csv"
    shell:
        "for f in {input}; do  stat -c '%n,%s' $f ; done >{output}"


rule compress:
    input:
        "fixed_size_{start}_{end}.none"
    output:
        "fixed_size_{start}_{end}.none.{compr}"
    params:
        exe=str(compr_exe)
    shell:
        "{params.exe} -ms_path fixed_size_{wildcards.start}_{wildcards.end}.none -compression {wildcards.compr}"

rule ms_blocks:
    input:
        ms_path
    output:
        ["fixed_size_%d_%d.none" % t for t in block_coords]
    shell:
        ("%s -len %d -block_type %s " % (split_exe, block_size, block_type) +
         "-ms_path {input} "
         "-out_prefix fixed_size -out_suffix .none -no_check 1 ")
