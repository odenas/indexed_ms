---
title: "New report"
author: "O. Denas"
date: "June 5, 2017"
output:
  pdf_document:
    toc: yes
  html_document:
    number_sections: yes
    toc: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message=FALSE)
```

```{r}
rm(list = ls())
library(tidyverse)
library(knitr)

qup <- function(x) quantile(x, 3/4)
qdown <- function(x) quantile(x, 1/4)

performance_boxplot <- function(p, tit){
  p + geom_boxplot(outlier.shape = 2, outlier.size = 0.5, outlier.colour = 'black') +
    geom_jitter(alpha=0.2, width=0.1) +
    theme(#axis.text.x = element_text(angle = 0, hjust = 1),
          legend.position="bottom") +
    labs(title = tit) + ylab("time_ms")
}

load_dsets <- function(dset_dir, cache, refresh=FALSE){
  if((!file.exists(cache)) || refresh){
    all_dt <- do.call(rbind, lapply(list.files(dset_dir, pattern = "*.csv"), function(fname){
      parts <- strsplit(fname, "_", fixed=TRUE)[[1]]
      
      read_csv(sprintf("%s/%s", dset_dir, fname)) %>% mutate(inp_type = sprintf("%s_%s", parts[1], parts[3]), alp=parts[5])
    }))
    message(sprintf("* dumping to %s", cache))
    saveRDS(all_dt, cache)
  }
  message(sprintf("* loading from %s", cache))
  readRDS(cache)
}

```



# Current performance -- not working
```{r, eval=FALSE}
res_pattern = list(small = 'rep_1000000s_sim_200000t_abcdefghijklmnopqrst_sim1000',
                   medium = 'rep_100000000s_sim_500000t_abcdefghijklmnopqrst_sim1000', 
                   big = '')

kable(read_csv(sprintf("../wl_tests/%s/rank_timing.csv", ".")) %>% 
  filter(measuring == "time", item == "ms_bvector") %>% 
  separate(b_path, into=c('stype', 'slen', 'ttype', 'tlen', 'alp', 'mp')) %>%
  unite(col = inp_type, stype, ttype, sep = "_") %>% 
  filter(alp == "abcdefghijklmnopqrst") %>% select(ntrial, value, label) %>% 
  group_by(label) %>% summarise(time_ms = mean(value)) %>% 
  separate(label, into=c("lazy", "fail", "maxrep")) %>% 
  mutate(lazy=ifelse(lazy == "l1", "lazy", "no-lazy"), 
         fail=ifelse(fail == "f1", "fail", "no-fail"), 
         maxrep=ifelse(maxrep == "m1", "maxrep", "no-maxrep")) %>% 
  arrange(time_ms), digits=0)
```

#Input properties
```{r}
input_stats_data <- (read_csv('../input_stats_data/stats.csv') %>% 
                       separate(b_path, into=c('stype', 'slen', 'ttype', 'tlen', 'alp', 'mp')))

node_data <- (input_stats_data %>% 
                filter(measuring == "wlnode_prop", where == "ms") %>% 
                separate(key, into=c('char', 'maxrep', 'has_wl', 'wide_i')) %>%
                unite(col = inp_type, stype, ttype, sep = "_") %>% 
                select(alp, wide_i, char, has_wl, maxrep, inp_type, value))
#node_data

pdata <- (input_stats_data %>% 
            filter(measuring == "consecutive_parent_calls", where == "ms") %>% 
            unite(col = inp_type, stype, ttype, sep = "_") %>% 
            select(inp_type, alp, key, value))
#pdata

wldata <- (input_stats_data %>% 
             filter(measuring == "consecutive_wl_calls", where == "ms") %>% 
             unite(col = inp_type, stype, ttype, sep = "_") %>% 
             select(inp_type, alp, key, value))
#wldata
```

All experiments are performed on the following inputs (the mutation period refers to the index sequence):

```{r, echo=FALSE}
kable(tibble(path = list.files("../datasets/big_paper2/", pattern = ".*.s$")) %>% 
        separate(path, into = c("s_type", "sl", "t_type", "tl", "alp", "mp", "suff")) %>% 
        separate(sl, into=c('slen', 'ssuff'), sep="s") %>% 
        separate(tl, into=c('tlen', 'tsuff'), sep="t") %>% 
        separate(mp, into=c('mpsuff', 'mutation_period'), sep="sim") %>% 
        select(s_type, t_type, slen, tlen, alp, mutation_period) %>% 
        mutate(slen = as.numeric(slen), tlen = as.numeric(tlen)), 
  caption = "Input datasets", 
  format.args = list(decimal.mark = ",", big.mark = "'", scientific=FALSE))
```

In this section, we run the matching statistics algorithm and gather information on the way. 


## Node properties
Before making a `wl(v, c)` call register whether `v` is a maximal repeat, and whether the Weiner link exists or not. 

```{r, echo=FALSE}
ggplot(node_data %>% 
         group_by(alp, maxrep, has_wl, inp_type) %>% 
         summarise(cnt = sum(value, na.rm = TRUE)) %>% 
         unite(ntp, maxrep, has_wl),
       aes(inp_type, cnt, fill=ntp, color=ntp)) + 
  geom_bar(stat='identity', position='dodge') +
  facet_wrap(~alp, ncol = 1)
```

## Consecutive wl() calls
During the MS vector construction, count the number of consecutive wl() calls due to matches between reversed indexed string and the query. In other words count the $k$-length iterations of the while cycle.

```{r, echo=FALSE}
ggplot(wldata %>% filter(inp_type %in% c('rep_dis', 'rep_sim')), 
       aes(factor(as.numeric(key)), value, color=alp)) + 
  geom_line(aes(group=alp), alpha=0.51) + geom_point(size=2) +
  facet_wrap(~inp_type, scale="free") + 
  theme(axis.text.x = element_text(angle = 90, hjust = 1, size=5), legend.position="bottom")  + 
  ylab("count") + xlab("wl() call sequence length")
```

## Consecutive parent() calls
During the MS vector construction, count the number of consecutive `parent()` calls after a failed `wl()` call.

```{r, echo=FALSE}
ggplot(pdata %>% filter(value > 0, inp_type != "rep_sim"), aes(factor(as.numeric(key)), value, color=alp)) + 
  #geom_bar(stat='identity', position='dodge') + 
  geom_line(aes(group=alp), alpha=0.51) + geom_point(size=2) +
  facet_wrap(~inp_type, scale="free") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, size=5), legend.position="bottom")

ggplot(pdata %>% filter(value > 0, inp_type == "rep_sim"), 
       aes((as.numeric(key)), value, color=alp)) + 
  geom_point(size=1, alpha=0.5) + scale_y_log10() + 
  ylab("log-scale count") + xlab("parent()  call sequence length") + 
  facet_wrap(~inp_type)
```


# wl() optimizations
## sandbox tests

```{r}
all_dt <- readRDS("../wl_tests/sandbox_maxrep/all_data.rds")

all_dt %>% group_by(close, method, is_maximal) %>% summarise(a = n())
#summary(all_dt)

summary(all_dt %>% filter(is_maximal == 0, close == 0))
ggplot(data = all_dt %>% filter(is_maximal == 0, close == 0, time_micro < 20), mapping = aes(method, time_micro)) + geom_boxplot() + labs(subtitle = "Non-maximal, large interval") + facet_wrap(~alp)

summary(all_dt %>% filter(is_maximal == 0, close == 1))
ggplot(data = all_dt %>% filter(is_maximal == 0, close == 1, time_micro < 10), mapping = aes(method, time_micro)) + geom_boxplot(outlier.shape = NA)  + labs(subtitle = "Non-maximal, small interval") + facet_wrap(~alp)

summary(all_dt %>% filter(is_maximal == 1, close == 0))
ggplot(data = all_dt %>% filter(is_maximal == 1, close == 0, time_micro < 20), mapping = aes(method, time_micro)) + geom_boxplot() + labs(subtitle = "Maximal, large interval") + facet_wrap(~alp)

summary(all_dt %>% filter(is_maximal == 1, close == 1))
ggplot(data = all_dt %>% filter(is_maximal == 1, close == 1, time_micro < 20), mapping = aes(method, time_micro)) + geom_boxplot() + labs(subtitle = "Maximal, small interval") + facet_wrap(~alp)
```


## full tests

I run the program several times with and without the optimization. The pointrange plots report (median, with quartile ranges) the relative difference of each optimized time from the average non-optimized time in the construction time of the MS vector which is 

$$
d^{(i)} = \frac{t^{(i)}_{\mathtt{opt}} - \bar{t}_{\mathtt{non\_opt}}}{\max\{t^{(i)}_{\mathtt{opt}}, \bar{t}_{\mathtt{non\_opt}}\}}
$$
with $\bar{t}_{\mathtt{non\_opt}} = 1/n \sum t^{(i)}_{\mathtt{non\_opt}}$. Hence negative values indicate a speedup by the optimization over the average non-optimized time: -0.5 is a 2x speedup etc, in general the speed up is $-1/d^{(i)}$. 

The boxplots report the raw times for the MS construction.

```{r, eval=FALSE}
time_data <- (read_csv(sprintf('../wl_tests/%s/rank_timing.csv', ".")) %>% 
                filter(measuring == "time", item == "ms_bvector") %>% 
                separate(b_path, into=c('stype', 'slen', 'ttype', 'tlen', 'alp', 'mp')) %>% 
                separate(label, into=c("lazy", "fail", "maxrep")) %>% 
                unite(col = inp_type, stype, ttype, sep = "_") %>% 
                mutate(lazy = ifelse(lazy == "l1", "lazy", "nonlazy"), 
                       fail = ifelse(fail == "f1", "fail", "nonfail"), 
                       maxrep = ifelse(maxrep == "m1", "maxrep", "nonmaxrep")) %>%
                select(ntrial, alp, lazy, fail, maxrep, inp_type, value))
```

## Lazy
```{r, eval=FALSE}
dt <- (time_data %>% filter(fail == "nonfail", maxrep == "nonmaxrep") %>% 
         #filter(inp_type %in% c('rep_dis', 'rep_sim')) %>% 
         select(lazy, ntrial, alp, inp_type, value))

ggplot(dt %>% 
         spread(key = lazy, value = value) %>%  
         group_by(alp, inp_type) %>% 
         mutate(rel_diff = (lazy - mean(nonlazy)) / pmax(lazy, mean(nonlazy))) %>%
         ungroup(), 
       aes(inp_type, rel_diff)) + 
  geom_pointrange(stat="summary", fatten = 1, fun.y=median, fun.ymin=qdown, fun.ymax=qup) +
  geom_jitter(alpha=0.1, width = 0.1) + geom_hline(yintercept = 0.0, color='blue') +
  facet_wrap(~alp) + ylim(-1, 1)

performance_boxplot(ggplot(dt, aes(inp_type, value, color=lazy)), "") + facet_grid(~alp)
```

## Fail
```{r, eval=FALSE}
dt <- (time_data %>% filter(lazy == "nonlazy", maxrep == "nonmaxrep") %>% 
         #filter(inp_type %in% c('rep_dis', 'rep_sim')) %>%
         select(fail, ntrial, alp, inp_type, value))

ggplot(dt %>% 
         spread(key = fail, value = value) %>%  
         group_by(alp, inp_type) %>% 
         mutate(rel_diff = (fail - mean(nonfail)) / pmax(fail, mean(nonfail))) %>%
         ungroup(), 
       aes(inp_type, rel_diff)) + 
  geom_pointrange(stat="summary", fatten = 1, fun.y=median, fun.ymin=qdown, fun.ymax=qup) +
  geom_jitter(alpha=0.1, width = 0.1) + geom_hline(yintercept = 0.0, color='blue') +
  facet_wrap(~alp) + ylim(-1, 1)

performance_boxplot(ggplot(dt, aes(inp_type, value, color=fail)), "") + facet_grid(~alp)
```

## maxrep
```{r, eval=FALSE}
dt <- (time_data %>% filter(lazy == "nonlazy", fail == "fail") %>% 
         select(maxrep, ntrial, alp, inp_type, value))

ggplot(dt %>% 
         spread(key = maxrep, value = value) %>% 
         group_by(alp, inp_type) %>% 
         mutate(rel_diff = (maxrep - mean(nonmaxrep)) / pmax(maxrep, mean(nonmaxrep))), 
       aes(inp_type, rel_diff)) + 
  #stat_summary(fun.y=median, fun.ymin=qdown, fun.ymax=qup, geom="errorbar") + 
  geom_pointrange(stat="summary", fatten = 1, fun.y=median, fun.ymin=qdown, fun.ymax=qup) +
  geom_jitter(alpha=0.1, width = 0.1) +
  geom_hline(yintercept = 0.0, color='blue') + 
  ylim(-1, 1) + facet_wrap(~alp)

performance_boxplot(ggplot(dt, aes(inp_type, value, color=maxrep)), "") + facet_grid(~alp)
```

# parent optimizations

```{r, eval=FALSE}
time_data <- (read_csv(sprintf('../parent_tests/%s/rank_timing.csv', params$bdir)) %>% 
                filter(measuring == "time", item == "ms_bvector") %>% 
                separate(b_path, into=c('stype', 'slen', 'ttype', 'tlen', 'alp', 'mp')) %>% 
                unite(col = inp_type, stype, ttype, sep = "_") %>% 
                mutate(time_ms = value) %>% 
                select(ntrial, alp, label, inp_type, time_ms))
#time_data
```

## sandbox analysis
For a given alphabet, input type, and parent call sequence length `k`, find node `v` and char `c` s.t. `wl(parent(v)^i, c)` does not exists for `i=0,...,k-1`, but `wl(u=parent(v)^k, c)` does exist. Register intervals of `v` and `u`, the time to get from `v` to `u` through the parent calls and the character `c`. 

Fit a model 

$$
t = b_0 + b_1 k
$$

with $t$ the running time of going from $v$ to $u=parent(v)^k$ (all input types have virtually the same coefficients).

```{r, eval=FALSE}
raw_sandbox_data <- (read_csv('../parent_tests/./sandbox_timing.csv') %>% 
             separate('filename', c("st", "sl", "tt", "tl", "alp", "mp", "sb", "suff")) %>% 
             unite(inp_type, st, tt) %>% 
             select(ntrial, cnt, seq_len, method, inp_type, alp, value)
)

sandbox_data <- raw_sandbox_data %>% 
  group_by(alp, method, inp_type) %>% 
  summarise(b0 = coef(lm(time_ms ~ seq_len, 
                        data=data.frame(seq_len = seq_len, time_ms = value / cnt)))[1],
            b1 = coef(lm(time_ms ~ seq_len, 
                        data=data.frame(seq_len = seq_len, time_ms = value / cnt)))[2]) %>%
  ungroup()
#sandbox_data

ggplot(raw_sandbox_data %>% filter(alp=='abcd', inp_type=='rep_dis'), aes(seq_len, value / cnt, color=method)) + 
  geom_smooth(method = "lm", se=FALSE) + geom_point() + 
  facet_grid(inp_type~alp) + expand_limits(x=0, y=0)

#summary(lm(value/cnt ~ seq_len, raw_sandbox_data %>% filter(method == "lca")))
#with(raw_sandbox_data %>% filter(method == "pseq"), plot(seq_len, value/cnt, xlim=c(0, 5), ylim=c(0, 0.003))); abline(a=(sandbox_data %>% filter(method == "pseq"))$b0, b = (sandbox_data %>% filter(method == "pseq"))$b1, col='blue'); grid()

analysis_dt <- (time_data %>% mutate(method = label) %>% group_by(alp, method, inp_type) %>% 
                  summarise(time_ms = mean(time_ms)) %>% 
                  inner_join(pdata %>% mutate(seq_len = as.numeric(key), cnt = value) %>%
                               select(alp, inp_type, seq_len, cnt), by=c('alp', 'inp_type')))
#analysis_dt

#b0 <- 0.00021454
#b1 <- 0.00000790
#sum((analysis_dt %>% filter(method == "lca") %>% mutate(aa = b0 + (seq_len * b1), bb = aa * cnt))$bb)

aa <- (analysis_dt %>% left_join(sandbox_data, by = c("alp", "method", "inp_type")) %>% 
    group_by(alp, method, inp_type) %>% 
    summarise(actual_time_ms = mean(time_ms),
              expected_time_ms = sum((b0 + seq_len * b1) * cnt)))
#aa
#ggplot(aa, aes(actual_time_ms, expected_time_ms, color=inp_type, shape=alp)) + geom_point() + geom_line()

bb <- (spread(aa %>% select(alp, method, inp_type, actual_time_ms), key=method, value="actual_time_ms") %>% mutate(actual_delta_t = lca - pseq) %>% 
    inner_join(spread(aa %>% select(alp, method, inp_type, expected_time_ms), key=method, value="expected_time_ms") %>% mutate(expected_delta_t = lca - pseq),
               by = c("alp", "inp_type")) %>% select(alp, inp_type, actual_delta_t, expected_delta_t)) %>% arrange(actual_delta_t)
#kable(bb, caption="delta: lca - pseq")
#ggplot(bb %>% filter, aes(expected_delta_t, actual_delta_t, color=inp_type)) + geom_point()
```

## Actual  runtime 
```{r, eval=FALSE}
ggplot(time_data %>% spread(key = label, value = time_ms) %>%  
         group_by(alp, inp_type) %>% 
         mutate(rel_diff = (lca - mean(pseq)) / pmax(lca, mean(pseq))), 
       aes(inp_type, rel_diff)) + 
  #stat_summary(fun.y=median, fun.ymin=qdown, fun.ymax=qup, geom="errorbar") + 
  geom_pointrange(stat="summary", fatten = 1, fun.y=median, fun.ymin=qdown, fun.ymax=qup) +
  geom_jitter(alpha=0.1, width = 0.1) +
  geom_hline(yintercept = 0.0, color='blue') + 
  ylim(-1, 1) + facet_wrap(~alp)

performance_boxplot(ggplot(time_data, aes(inp_type, time_ms, color=label)), "") + facet_grid(~alp)
```


# Parallelization
Run the program on 1, 2, 4, 8 and 16 threads and measure the time it takes to build the RUNS and MS vectors.

> TODO: there is currently a bug on the parallel version of the program when the 
> input has stretches of perfect match that span a whole block.

```{r, eval=FALSE}
time_data <- (read_csv(sprintf('../parallelization_data/%s/stats.csv', params$bdir)) %>% 
                filter(measuring == "time", item %in% c("ms_bvector", "runs_bvector")) %>% 
                separate(b_path, into=c('stype', 'slen', 'ttype', 'tlen', 'alp', 'mp')) %>% 
                unite(col = inp_type, stype, ttype, sep = "_") %>% 
                spread(key = item, value = value) %>% 
                mutate(value = ms_bvector + runs_bvector) %>% 
                select(ntrial, alp, label, inp_type, value))




ggplot(time_data %>% group_by(label, alp, inp_type) %>% summarise(min_time = min(value),
                                                           max_time = max(value),
                                                           avg_time = mean(value)),
       aes(factor(label), avg_time, color=inp_type)) + 
  geom_errorbar(aes(ymin=min_time, ymax=max_time), width = 0.1) + 
  geom_line(aes(group = inp_type)) + geom_point() + 
  facet_wrap(~alp)
```




