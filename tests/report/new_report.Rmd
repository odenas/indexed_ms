---
title: "New report"
author: "O. Denas"
date: "June 5, 2017"
output:
  pdf_document:
    number_sections: yes
    toc: yes
  html_document:
    df_print: tibble
    number_sections: yes
    toc: yes
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message=FALSE)
```

```{r utilities}
rm(list = ls())
library(tidyverse)
library(knitr)
library(ggridges)

performance_boxplot <- function(p, tit){
  p + geom_boxplot(outlier.shape = 2, outlier.size = 0.5, outlier.colour = 'black') +
    geom_jitter(alpha=0.2, width=0.1) +
    theme(#axis.text.x = element_text(angle = 0, hjust = 1),
          legend.position="bottom") +
    labs(title = tit) + ylab("time_ms")
}

prange_plot <- function(dt){
  qup <- function(x) quantile(x, 3/4)
  qdown <- function(x) quantile(x, 1/4)
  
  ggplot(dt, aes(inp_type, rel_diff)) + 
    geom_pointrange(stat = "summary", fatten = 1, fun.y = median, fun.ymin = qdown, fun.ymax = qup) +
    geom_jitter(alpha=0.1, width = 0.1) + 
    geom_hline(yintercept = 0.0, color='blue') +
    facet_grid(~alp) + 
    ylim(-1, 1)
}
```



# Current performance -- not working
```{r, eval=FALSE}
res_pattern = list(small = 'rep_1000000s_sim_200000t_abcdefghijklmnopqrst_sim1000',
                   medium = 'rep_100000000s_sim_500000t_abcdefghijklmnopqrst_sim1000', 
                   big = '')

kable(read_csv(sprintf("../wl_tests/%s/rank_timing.csv", ".")) %>% 
  filter(measuring == "time", item == "ms_bvector") %>% 
  separate(b_path, into=c('stype', 'slen', 'ttype', 'tlen', 'alp', 'mp')) %>%
  unite(col = inp_type, stype, ttype, sep = "_") %>% 
  filter(alp == "abcdefghijklmnopqrst") %>% select(ntrial, value, label) %>% 
  group_by(label) %>% summarise(time_ms = mean(value)) %>% 
  separate(label, into=c("lazy", "fail", "maxrep")) %>% 
  mutate(lazy=ifelse(lazy == "l1", "lazy", "no-lazy"), 
         fail=ifelse(fail == "f1", "fail", "no-fail"), 
         maxrep=ifelse(maxrep == "m1", "maxrep", "no-maxrep")) %>% 
  arrange(time_ms), digits=0)
```

#Input properties
```{r}
input_stats_data <- (read_csv('../input_stats_data/stats.csv') %>% 
                       separate(b_path, into=c('stype', 'slen', 'ttype', 'tlen', 'alp', 'ext')) %>% 
                       select(-len_s, -len_t, -ext))

node_data <- (input_stats_data %>% 
                filter(measuring == "wl_calls", where == "ms") %>% 
                separate(key, into=c('char', 'maxrep', 'has_wl', 'wide_i')) %>%
                unite(col = inp_type, stype, ttype, sep = "_") %>% 
                select(alp, wide_i, char, has_wl, maxrep, inp_type, value))
#node_data

pdata <- (input_stats_data %>% 
            filter(measuring == "pseq") %>% mutate(key = as.numeric(key)) %>% 
            unite(col = inp_type, stype, ttype, sep = "_") %>% 
            select(inp_type, alp, key, value))
#pdata

wldata <- (input_stats_data %>% 
             filter(measuring == "wlseq", where == "ms") %>% mutate(key = as.numeric(key)) %>% 
             unite(col = inp_type, stype, ttype, sep = "_") %>% 
             select(inp_type, alp, key, value))
#wldata
```

All experiments are performed on the following inputs (the mutation period refers to the index sequence):

```{r, echo=FALSE}
kable(tibble(path = list.files("../datasets/big_paper3/", pattern = ".*.s$")) %>% 
        separate(path, into = c("s_type", "sl", "t_type", "tl", "alp", "suff")) %>% 
        separate(sl, into=c('slen', 'ssuff'), sep="s") %>% 
        separate(tl, into=c('tlen', 'tsuff'), sep="t") %>% 
        select(s_type, t_type, slen, tlen, alp) %>% 
        mutate(slen = as.numeric(slen), tlen = as.numeric(tlen)), 
  caption = "Input datasets", 
  format.args = list(decimal.mark = ",", big.mark = "'", scientific=FALSE))
```

In this section, we run the matching statistics algorithm and gather information on the way. 


## Node properties
Before making a `wl(v, c)` call register whether `v` is a maximal repeat, and whether the Weiner link exists or not. 

```{r, echo=FALSE}
node_data <- node_data %>% 
  group_by(alp, maxrep, has_wl, inp_type) %>% 
  summarise(cnt = sum(value, na.rm = TRUE)) %>% 
  unite(ntp, maxrep, has_wl)

ggplot(node_data, aes(inp_type, cnt, fill=ntp)) + 
  geom_bar(stat='identity', position='dodge') + facet_wrap(~alp, ncol = 1) 

ggplot(node_data, aes(inp_type, cnt, fill=ntp)) + 
  geom_bar(stat='identity', position='dodge') + facet_wrap(~alp, ncol = 1) + scale_y_log10() + ylab("cnt in log10 scale")
```

## Consecutive wl() calls
During the MS vector construction, count the number of consecutive wl() calls due to matches between reversed indexed string and the query. In other words count the $k$-length iterations of the while cycle.

```{r, echo=FALSE}
#data.frame(wldata %>% filter(inp_type %in% c('rep_sim', 'rnd_sim')))

ggplot(wldata %>% filter(inp_type %in% c('rep_sim', 'rnd_sim')), 
       aes(as.numeric(key), value, color=alp)) + 
  geom_line(aes(group=alp), alpha=0.51) + geom_point(size=2) +
  facet_wrap(~inp_type, scale="free") + 
  theme(axis.text.x = element_text(angle = 90, hjust = 1, size=5), legend.position="bottom")  + 
  ylab("count") + xlab("wl() call sequence length")

ggplot(wldata %>% filter(inp_type %in% c('rep_dis', 'rnd_dis')), 
       aes(factor(as.numeric(key)), value, color=alp)) + 
  geom_line(aes(group=alp), alpha=0.51) + geom_point(size=2) +
  facet_wrap(~inp_type, scale="free") + 
  theme(axis.text.x = element_text(angle = 90, hjust = 1, size=5), legend.position="bottom")  + 
  ylab("count") + xlab("wl() call sequence length")

```

## Consecutive parent() calls
During the MS vector construction, count the number of consecutive `parent()` calls after a failed `wl()` call.

```{r, echo=FALSE}
#data.frame(pdata %>% filter(inp_type %in% c('rep_sim', 'rnd_sim')))

ggplot(pdata %>% filter(inp_type %in% c('rep_sim', 'rnd_sim')), 
       aes(key, value, color=alp)) + 
  geom_line(aes(group=alp), alpha=0.51) + geom_point(size=2) +
  facet_wrap(~inp_type, scale="free") + 
  theme(axis.text.x = element_text(angle = 90, hjust = 1, size=5), legend.position="bottom")  + 
  ylab("count") + xlab("parent() call sequence length")

ggplot(pdata %>% filter(inp_type %in% c('rep_dis', 'rnd_dis')), 
       aes(factor(as.numeric(key)), value, color=alp)) + 
  geom_line(aes(group=alp), alpha=0.51) + geom_point(size=2) +
  facet_wrap(~inp_type, scale="free") + 
  theme(axis.text.x = element_text(angle = 90, hjust = 1, size=5), legend.position="bottom")  + 
  ylab("count") + xlab("parent() call sequence length")
```


# wl() optimizations

## sandbox tests
The 4 plots correspond to combinations of index size (one 100Mb and one 1Mb) and alphabet size (one 4 and one 20). Each plot shows 6 measurements based on 

 * node type: leaf (l) or internal (i)
 * maximality: maximal (m) or non-maximal (nm)
 * WL presence: present (wlp) or absent (wla)


```{r wl_sandbox_setup}

alps <- "abcd"
alpl <- "abcdefghijklmnopqrst"

big_dt <- do.call(rbind, lapply(c(alps, alpl), function(a){
  p <- sprintf('../wl_tests/sandbox_maxrep/rep_100000000s_sim_500000t_%s.s.csv', a)
  read_csv(p) %>% mutate(alp = ifelse(a==alps, "small_alp", "large_alp"))
})) %>% mutate(dset="large_dset")

all_dt <- (big_dt %>% 
             mutate(tcall = t_micro / ncalls, 
                    maximal=ifelse(maximal == 1, "m", "nm"), 
                    has_wl=ifelse(has_wl == 1, "wlp", "wla"),
                    node=ifelse(node == 1, "i", "l")) %>% 
             unite(tp, node, maximal, has_wl)) %>% filter(dset == 'large_dset')
```

```{r}
ggplot(all_dt %>% filter(alp=="large_alp"), aes(tp, tcall, fill=method)) + 
  geom_boxplot(position='dodge') + facet_wrap(~dset, ncol=1, scales = "free_y") + 
  labs(subtitle = "Large(20) alphabet")
```

```{r}
ggplot(all_dt %>% filter(alp=="small_alp"), aes(tp, tcall, fill=method)) +
  geom_boxplot(position='dodge') + facet_wrap(~dset, ncol=1, scales = "free_y") + 
  labs(subtitle = "Small(4) alphabet")

#ggplot(all_dt %>% filter(alp=="large_alp"), aes(tp, tcall, fill=method)) + geom_boxplot(position='dodge') + facet_wrap(~dset, ncol=1, scales = "free_y") + theme(axis.text.x = element_text(angle = 10, hjust = 1)) + labs(subtitle = "Large(20) alphabet")
```

<!--Below is the same data shown as densities. So, each density curve here corresponds to a box in the boxplot above.-->

```{r, eval=FALSE}

ggplot(all_dt %>% filter(dset=="small_dset", alp=="small_alp"), aes(x = tcall, y = method)) + 
  geom_density_ridges() + facet_wrap(~tp, scales='free', ncol = 2)

ggplot(all_dt %>% filter(dset=="small_dset", alp=="large_alp"), aes(x = tcall, y = method)) + 
  geom_density_ridges() + facet_wrap(~tp, ncol = 2)

ggplot(all_dt %>% filter(dset=="large_dset", alp=="small_alp"), aes(x = tcall, y = method)) + 
  geom_density_ridges() + facet_wrap(~tp, scales='free', ncol = 2)

ggplot(all_dt %>% filter(dset=="large_dset", alp=="large_alp"), aes(x = tcall, y = method)) + 
  geom_density_ridges() + facet_wrap(~tp, ncol = 2)
```

## full tests

I run the program several times with and without the optimization. The pointrange plots report (median, with quartile ranges) the relative difference of each optimized time from the average non-optimized time in the construction time of the MS vector which is 

$$
d^{(i)} = \frac{t^{(i)}_{\mathtt{opt}} - \bar{t}_{\mathtt{non\_opt}}}{\max\{t^{(i)}_{\mathtt{opt}}, \bar{t}_{\mathtt{non\_opt}}\}}
$$
with $\bar{t}_{\mathtt{non\_opt}} = 1/n \sum t^{(i)}_{\mathtt{non\_opt}}$. Hence negative values indicate a speedup by the optimization over the average non-optimized time: -0.5 is a 2x speedup etc, in general the speed up is $-1/d^{(i)}$. 

The boxplots report the raw times for the MS construction.

```{r fulltest_data}
time_data <- (read_csv('../wl_tests/rank_timing.csv') %>% 
                filter(item %in% c("ms_bvector", "runs_bvector")) %>% 
                separate(b_path, into=c('stype', 'slen', 'ttype', 'tlen', 'alp')) %>% 
                separate(label, into=c("lazy", "fail", "drank", "maxrep")) %>% 
                unite(col = inp_type, stype, ttype, sep = "_") %>% 
                mutate(lazy = ifelse(lazy == "l1", "lazy", "nonlazy"), 
                       fail = ifelse(fail == "f1", "fail", "nonfail"),
                       drank = ifelse(drank == "r0", "srank", "drank"),
                       maxrep = ifelse(maxrep == "m0", "nonmaxrep", 
                                       ifelse(maxrep == "m1", "maxrep_vanilla", "maxrep_rc"))) %>%
                select(ntrial, alp, item, lazy, fail, drank, maxrep, inp_type, value))
# filter(ntrial == 1, alp=='abcd', inp_type=='rep_sim', maxrep=='nonmaxrep') %>% 
time_data <- time_data %>% spread(item, value) %>% mutate(bvector = ms_bvector + runs_bvector, value = bvector)
```




### drank
```{r drank_plot_better}
dt <- (time_data %>% filter(maxrep == "nonmaxrep", fail=="nonfail"))
dt %>% group_by(drank) %>% summarise(a = n())
prange_plot(dt %>% 
              select(drank, lazy, ntrial, alp, inp_type, value) %>% spread(key = drank, value = value) %>%  
              group_by(lazy, alp, inp_type) %>% 
              mutate(rel_diff = (drank - mean(srank)) / pmax(drank, mean(srank))) %>%
              ungroup()) #+ geom_jitter(aes(color=lazy), alpha=0.8)
performance_boxplot(ggplot(dt, aes(inp_type, value, color=drank)), "") + facet_grid(~alp)
```

### Lazy
```{r lazy_plot}
dt <- time_data %>% filter(maxrep == "nonmaxrep")
dt %>% group_by(lazy) %>% summarise(a = n())

prange_plot(dt %>% 
              select(drank, fail, lazy, ntrial, alp, inp_type, value) %>% 
              spread(key = lazy, value = value) %>%
              group_by(drank, fail, alp, inp_type) %>% 
              mutate(rel_diff = (lazy - mean(nonlazy)) / pmax(lazy, mean(nonlazy))) %>%
              ungroup()) #+ geom_jitter(aes(color=drank), alpha=0.8)
performance_boxplot(ggplot(dt, aes(inp_type, value, color=lazy)), "") + facet_grid(~alp)
```

### Fail
```{r fail_plot1}
dt <- (time_data %>% filter(maxrep == "nonmaxrep", drank=="drank"))
dt %>% group_by(fail) %>% summarise(a = n())

prange_plot(dt %>% 
              select(lazy, fail, ntrial, alp, inp_type, value) %>% spread(key = fail, value = value) %>%  
              group_by(lazy, alp, inp_type) %>% 
              mutate(rel_diff = (fail - mean(nonfail)) / pmax(fail, mean(nonfail))) %>%
              ungroup()) #+ geom_jitter(aes(color=lazy), alpha=0.8)
performance_boxplot(ggplot(dt, aes(inp_type, value, color=fail)), "") + facet_grid(~alp)
```



### all flags (lazy, fail, double_rank) vs. single rank
```{r allflags_plot}
dt <- rbind((time_data %>% filter(fail=='fail',    lazy == "lazy",    drank=='drank', maxrep == "nonmaxrep")),
            (time_data %>% filter(fail=='nonfail', lazy == "nonlazy", drank=='srank', maxrep == "nonmaxrep")))
dt %>% group_by(drank) %>% summarise(a = n())

prange_plot(dt %>% 
              select(drank, ntrial, alp, inp_type, value) %>% spread(key = drank, value = value) %>%  
              group_by(alp, inp_type) %>% 
              mutate(rel_diff = (drank - mean(srank)) / pmax(drank, mean(srank))) %>%
              ungroup())
performance_boxplot(ggplot(dt, aes(inp_type, value, color=fail)), "") + facet_grid(~alp)
```

### maxrep
#### maxrep_vanilla vs. non-maxrep
```{r maxrep1_plot}
dt <- (time_data %>% filter(lazy == "nonlazy", fail == "fail", drank=='drank', maxrep != 'maxrep_rc'))
dt %>% group_by(maxrep) %>% summarise(a = n())

prange_plot(dt %>% 
              select(maxrep, ntrial, alp, inp_type, value) %>% 
              spread(key = maxrep, value = value) %>% 
              group_by(alp, inp_type) %>% 
              mutate(rel_diff = (maxrep_vanilla - mean(nonmaxrep)) / pmax(maxrep_vanilla, mean(nonmaxrep))) %>% 
              ungroup())
performance_boxplot(ggplot(dt, aes(inp_type, value, color=maxrep)), "") + facet_grid(~alp)
```

#### maxrep+rank_and_check vs. non-maxrep
```{r maxrep2_plot}
dt <- (time_data %>% filter(lazy == "nonlazy", fail == "fail", drank=='drank', maxrep != 'maxrep_vanilla'))
dt %>% group_by(maxrep) %>% summarise(a = n())

prange_plot(dt %>% 
              select(maxrep, ntrial, alp, inp_type, value) %>% 
              spread(key = maxrep, value = value) %>% 
              group_by(alp, inp_type) %>% 
              mutate(rel_diff = (maxrep_rc - mean(nonmaxrep)) / pmax(maxrep_rc, mean(nonmaxrep))) %>% 
              ungroup())
performance_boxplot(ggplot(dt, aes(inp_type, value, color=maxrep)), "") + facet_grid(~alp)
```

#### maxrep+rank_and_check vs. maxrep_vanilla
```{r maxrep3_plot}
dt <- (time_data %>% filter(lazy == "nonlazy", fail == "fail", drank=='drank', maxrep != 'nonmaxrep'))
dt %>% group_by(maxrep) %>% summarise(a = n())
prange_plot(dt %>% 
              select(maxrep, ntrial, alp, inp_type, value) %>% 
              spread(key = maxrep, value = value) %>% 
              group_by(alp, inp_type) %>% 
              mutate(rel_diff = (maxrep_rc - mean(maxrep_vanilla)) / pmax(maxrep_rc, mean(maxrep_vanilla))) %>% 
              ungroup())
performance_boxplot(ggplot(dt, aes(inp_type, value, color=maxrep)), "") + facet_grid(~alp)
```




# parent optimizations
## sandbox tests

### select at dist 
Traverse the tree and time the call `select_at_dist` (labeled f)  and the call  `select(rank())` (labeled s) on each node.

```{r select_at_dist_sandbox}
#all_dt <- readRDS("../parent_tests/sandbox_selectatdist/all_data.rds")

#ggplot(all_dt %>% filter(dist < 500) %>% group_by(dist, method, inp_type, alp) %>% summarise(time_micro = mean(time_micro)), aes(dist, time_micro, color=method)) + geom_smooth(method="loess", span=0.05, aes(fill=method)) + facet_grid(alp~inp_type)

#ggplot(all_dt %>% filter(dist < 2000) %>% group_by(dist, method, inp_type, alp) %>% summarise(time_micro = mean(time_micro)), aes(dist, time_micro, color=method)) + geom_smooth(method="loess", span=0.05, aes(fill=method)) + facet_wrap(alp~inp_type)

#ggplot(all_dt %>% group_by(dist, method, inp_type) %>% summarise(time_micro = mean(time_micro)), aes(dist, time_micro, color=method)) + geom_smooth(method="loess", span=0.05, aes(fill=method)) + facet_wrap(~inp_type)


sdd <- readRDS('../parent_tests/sandbox_selectatdist/group_data.rds') %>% filter(dist < 250)
ggplot(data=sdd, aes(x=dist, y=time_avg, colour=method)) + geom_line() + geom_ribbon(aes(ymin=time_avg - time_sd, ymax=time_avg + time_sd, fill=method), linetype=0, alpha=0.1) + facet_grid(alp~inp_type, scales = "free_y") + ylim(-1, 3)
```

### lowest maximal ancestor
Generate all tuples `(v, c, d)` from a tree where, `n` is an internal node, `c` a character, and `d = depth(v) - depth(u)` with `u` the lowest maximal ancestor.

Then shuffle and time the two ways of finding `u`: using the maxrep or with a sequence of parent calls.

The plots show the `total time / nr of calls` for a given depth with the size of the point representing the  `nr of calls` for a given depth value.

When the nr of calls is small (this happens for large depth lengths) the time resolution is not big enough and the numbers are not to be trusted -- hence I have removed the data from the plots. 

```{r parent_sandbox}
all_dt <- (read_csv("../parent_tests/sandbox_parent/all.csv") %>% 
             separate(filename, c('st', 'sl', 'tt', 'tl', 'alp', 'other')) %>%
             select(-other, -st, -tt, -tl) %>% 
             mutate(sl = ifelse(sl == "1000000s", "small", "big")) %>% 
             filter(nwd_cnt > 200))

dd <- all_dt %>% filter(alp=='abcd', sl=="big")
ggplot(dd, aes(parent_depth, value/nwd_cnt, color=method)) + geom_line() + geom_point(aes(size=nwd_cnt)) + labs(subtitle = "Small(4) alphabet, big index(100Mb)")


dd <- all_dt %>% filter(alp!='abcd', sl=="big")
ggplot(dd, aes(parent_depth, value/nwd_cnt, color=method)) + geom_line() + geom_point(aes(size=nwd_cnt)) + labs(subtitle = "Big(20) alphabet, big index(100Mb)")
```

By counting the number of consecutive parent calls (for each number of consecutive calls) we project the runtime of each method for an input type as below.

```{r expected_times}
dd <- all_dt %>% filter(sl=="big")
p_stats <- pdata %>% mutate(parent_depth = key, cnt = value) %>% select(-key, -value)
expected_data <- (left_join(p_stats, dd, by = c("parent_depth", "alp")) %>% 
                    mutate(expected_time = cnt * value) %>% filter(!is.na(method)))

ggplot(expected_data %>% mutate(expected_time = cnt * value),
       aes(parent_depth, expected_time, fill=method)) + 
  geom_bar(position='dodge', stat='identity') + facet_wrap(alp~inp_type, scales = "free")
```


## full tests
```{r parent_full}
time_data <- (read_csv("../parent_tests/rank_timing.csv") %>% 
                filter(item  == "ms_bvector") %>% 
                separate(b_path, into=c('stype', 'slen', 'ttype', 'tlen', 'alp')) %>% 
                unite(col = inp_type, stype, ttype, sep = "_") %>% 
                spread(key = item, value = value) %>% 
                select(ntrial, label, inp_type, alp, ms_bvector))
#time_data


prange_plot(time_data %>% spread(key = label, value = ms_bvector) %>%  group_by(alp, inp_type) %>% mutate(rel_diff = (lca - mean(pseq)) / pmax(lca, mean(pseq))))
performance_boxplot(ggplot(time_data, aes(inp_type, ms_bvector, color=label)), "") + facet_grid(~alp)
```


# parallelization
Run the program on 1, 2, 4, 8 and 16 threads and measure the time it takes to build the RUNS and MS vectors.

> TODO: there is currently a bug on the parallel version of the program for particular inputs. At the moment 
> fixing it is not a priority.


```{r, eval=FALSE}
time_data <- (read_csv(sprintf('../parallelization_data/%s/stats.csv', params$bdir)) %>% 
                filter(measuring == "time", item %in% c("ms_bvector", "runs_bvector")) %>% 
                separate(b_path, into=c('stype', 'slen', 'ttype', 'tlen', 'alp', 'mp')) %>% 
                unite(col = inp_type, stype, ttype, sep = "_") %>% 
                spread(key = item, value = value) %>% 
                mutate(value = ms_bvector + runs_bvector) %>% 
                select(ntrial, alp, label, inp_type, value))

ggplot(time_data %>% group_by(label, alp, inp_type) %>% summarise(min_time = min(value),
                                                           max_time = max(value),
                                                           avg_time = mean(value)),
       aes(factor(label), avg_time, color=inp_type)) + 
  geom_errorbar(aes(ymin=min_time, ymax=max_time), width = 0.1) + 
  geom_line(aes(group = inp_type)) + geom_point() + 
  facet_wrap(~alp)
```




